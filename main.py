

from openai import AsyncOpenAI
from dotenv import load_dotenv
import os

from pydub import AudioSegment
import logging
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters, CallbackContext
import speech_recognition as sr

from bot.start_handler import start
from bot.question_command import conv_handler

load_dotenv()
TOKEN = os.getenv("TELEGRAM_TOKEN")
API_KEY = os.getenv("CHATGPT_API")
dataDirPath = os.path.join(os.path.dirname(os.path.realpath(__file__)), "data")



logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)



client = AsyncOpenAI(api_key=API_KEY)
# async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     await context.bot.send_message(chat_id=update.effective_chat.id, text="Hi, what's up?")

async def echo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    ch = [
        {"role": "user", "content": str(update.message.text)}
    ]
    response = await chat(MSGS=ch, MaxToken=500, outputs=3)
    await context.bot.send_message(chat_id=update.effective_chat.id, text=response)


async def audio(update: Update, context: CallbackContext) -> None:
    file = await context.bot.get_file(update.message.voice)
    await file.download_to_drive(os.path.join(dataDirPath,"user_audio.ogg"))
    ogg_audio = AudioSegment.from_file(os.path.join(dataDirPath,"user_audio.ogg"), format="ogg")
    ogg_audio.export(os.path.join(dataDirPath,"user_audio.wav"), format='wav')
    r = sr.Recognizer()
    with sr.AudioFile(os.path.join(dataDirPath,"user_audio.wav")) as source:
        audio_data = r.record(source)
        text = r.recognize_google(audio_data)
    ch = [
        {"role": "user", "content": str(text)}
    ]
    response = await chat(MSGS=ch, MaxToken=500, outputs=3)
    await update.message.reply_text(response)

async def chat(MSGS: list, MaxToken: int=50, outputs: int=3) -> str:
    # We use the Chat Completion endpoint for chat like inputs
    response = await client.chat.completions.create(
    # gpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314,
    # gpt-3.5-turbo, gpt-3.5-turbo-0301
    model="gpt-3.5-turbo",
    # MSGS=[
    #     {"role": "system", "content": "<message generated by system>"},
    #     {"role": "user", "content": "<message generated by user>"},
    #     {"role": "assistant", "content": "<message generated by assistant>"}
    # ]
    messages=MSGS,
    # max_tokens generated by the AI model
    # maximu value can be 4096 tokens for "gpt-3.5-turbo"
    max_tokens = MaxToken,
    # number of output variations to be generated by AI model
    n = outputs,
    )
    return response.choices[0].message.content

if __name__ == '__main__':
    application = ApplicationBuilder().token(TOKEN).build()
    start_handler = CommandHandler('start', start)
    # question_handler = CommandHandler("question", conv_handler)
    # echo_handler = MessageHandler(filters.TEXT & (~filters.COMMAND), echo)
    # audio_handler = MessageHandler(filters.VOICE & ~filters.COMMAND, audio)

    application.add_handler(start_handler)
    # application.add_handler(echo_handler)
    application.add_handler(conv_handler)
    # application.add_handler(question_handler)
    application.run_polling(allowed_updates=Update.ALL_TYPES)






